{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from random import shuffle, randint\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in csv file\n",
    "data = pd.read_csv(\"wine.csv\", header=None)\n",
    "trainPercent = 40 #must be between 0 and 100\n",
    "validationPercent = 35\n",
    "lmbda = .00001\n",
    "numberRowsOfClass1 = 59\n",
    "numberRowsOfClass2 = 71\n",
    "numberRowsOfClass3 = 48\n",
    "data.head() #look at first 5 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grab desired inputs to test one. Build a dataframe from them.\n",
    "dataInputs= data.loc[:,1:13]\n",
    "dataInputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grab the expected outputs. (This is supervised learning)\n",
    "y1=[]\n",
    "y2=[]\n",
    "y3=[]\n",
    "for i in range(0,numberRowsOfClass1):\n",
    "    y1.append([1,0,0]);#class1\n",
    "for j in range(0, numberRowsOfClass2):\n",
    "    y2.append([0,1,0]);#class2\n",
    "for k in range(0, numberRowsOfClass3):\n",
    "    y3.append([0,0,1]);#Class3\n",
    "expectedOutput=np.concatenate([y1,y2,y3])\n",
    "expectedOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 13)\n",
      "(24, 3)\n",
      "(47, 13)\n",
      "(47, 3)\n",
      "(107, 13)\n",
      "(107, 3)\n",
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n",
      "ValidateTest [[1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n",
      "[[ 1  0  0 36]\n",
      " [ 0  0  1 28]\n",
      " [ 0  1  0 43]]\n",
      "[[1 0 0 7]\n",
      " [0 1 0 9]\n",
      " [0 0 1 8]]\n",
      "36\n",
      "43\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "#Hint: use train_test_split\n",
    "inputTrain, inputTest, expectedOutputTrain, expectedOutputTest = train_test_split(dataInputs, expectedOutput, train_size = trainPercent/100, random_state=42)\n",
    "validateTest, inputTrain, validateOutputTest, expectedOutputTrain = train_test_split(inputTrain, expectedOutputTrain, train_size = validationPercent/100, random_state=42)\n",
    "#inputTest.head()\n",
    "print(validateTest.shape)\n",
    "print(validateOutputTest.shape)\n",
    "print(inputTrain.shape)\n",
    "print(expectedOutputTrain.shape)\n",
    "print(inputTest.shape)\n",
    "print(expectedOutputTest.shape)\n",
    "\n",
    "def getClassCountTotals(output):\n",
    "    d = collections.OrderedDict()\n",
    "    for a in output:\n",
    "        t = tuple(a)\n",
    "        if t in d:\n",
    "            d[t] += 1\n",
    "        else:\n",
    "            d[t] = 1\n",
    "\n",
    "    result = []\n",
    "    for (key, value) in d.items():\n",
    "        result.append(list(key) + [value])\n",
    "\n",
    "    B = np.asarray(result)\n",
    "    print(B)\n",
    "    for Bi in B:\n",
    "        if Bi[0] == 1:\n",
    "            class1Total = Bi[3]\n",
    "        elif Bi[1] == 1:\n",
    "            class2Total = Bi[3]\n",
    "        elif Bi[2] == 1:\n",
    "            class3Total = Bi[3]\n",
    "    return class1Total, class2Total, class3Total\n",
    "print(expectedOutputTest)\n",
    "print(\"ValidateTest\",validateOutputTest)\n",
    "class1Total, class2Total, class3Total = getClassCountTotals(expectedOutputTest)\n",
    "validationCounts = getClassCountTotals(validateOutputTest)\n",
    "print(class1Total)\n",
    "print(class2Total)\n",
    "print(class3Total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build our least squares classifier for 2 classes\n",
    "D = inputTrain.shape[1] + 1 #num of attributes, +1 is for the intercept (column of 1s)\n",
    "K = expectedOutput.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expectedOutputTrain = np.asarray(expectedOutputTrain)\n",
    "expectedOutputTest = np.asarray(expectedOutputTest)\n",
    "inputTrain = np.asarray(inputTrain)\n",
    "inputTest = np.asarray(inputTest)\n",
    "validateTest = np.asarray(validateTest)\n",
    "validateOutputTest = np.asarray(validateOutputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum1 = 0\n",
    "sum2 = 0\n",
    "def createWeightMatrix(x, y, lmbda):\n",
    "    numRows = x.shape[0]\n",
    "    print(\"y\", y)\n",
    "    new_col = np.ones((numRows,1))\n",
    "    augmentedX = np.c_[new_col, x]\n",
    "    sum1 = np.dot(augmentedX.T, augmentedX) + lmbda\n",
    "    sum2 = np.dot(augmentedX.T, y)\n",
    "    W = np.dot(np.linalg.inv(sum1), sum2)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classificationTest(xTest, yTest, W, isValidating):  \n",
    "    returnVals = []\n",
    "    total = yTest.shape[0]\n",
    "    predicted = np.zeros((total, K))\n",
    "    i=0\n",
    "    class1Correct=class2Correct=class3Correct=totalCorrect=0\n",
    "    correctPredictionCol = [0]*total\n",
    "    for i in range(total):      \n",
    "        x = xTest[i]        \n",
    "        x = np.append(1,x)         \n",
    "        x = x.reshape(1,D)        \n",
    "        values = np.dot(W.T,x.T)\n",
    "        values = values.T\n",
    "        values = values.flatten()\n",
    "        maxIndex = np.argmax(values)\n",
    "        if yTest[i][maxIndex] == 1:\n",
    "            if maxIndex == 0:\n",
    "                class1Correct += 1\n",
    "            elif maxIndex == 1:\n",
    "                class2Correct += 1\n",
    "            elif maxIndex == 2:\n",
    "                class3Correct += 1\n",
    "            correctPredictionCol[i] = 1\n",
    "        predicted[i][maxIndex] = 1\n",
    "    totalCorrect = class1Correct + class2Correct + class3Correct\n",
    "    print(totalCorrect)\n",
    "    totalAccuracy=totalCorrect/float(total)*100\n",
    "    if isValidating == False:\n",
    "        class1Accuracy = class1Correct/float(class1Total)*100\n",
    "        class2Accuracy = class2Correct/float(class2Total)*100\n",
    "        class3Accuracy = class3Correct/float(class3Total)*100\n",
    "        print(\"class1 misclassification error = \", 100 - class1Accuracy)\n",
    "        print(\"class2 misclassification error = \", 100 - class2Accuracy)\n",
    "        print(\"class3 misclassification error = \", 100 - class3Accuracy)\n",
    "    else:\n",
    "        class1Accuracy = class1Correct/float(validationCounts[0])*100\n",
    "        class2Accuracy = class2Correct/float(validationCounts[1])*100\n",
    "        class3Accuracy = class3Correct/float(validationCounts[2])*100\n",
    "        print(\"class1 misclassification error = \", 100 - class1Accuracy)\n",
    "        print(\"class2 misclassification error = \", 100 - class2Accuracy)\n",
    "        print(\"class3 misclassification error = \", 100 - class3Accuracy)\n",
    "    print(\"total misclassification error = \", 100 - totalAccuracy)\n",
    "    print(total)\n",
    "    returnVals.append(100-totalAccuracy)\n",
    "    returnVals.append(predicted)\n",
    "    returnVals.append(correctPredictionCol)\n",
    "    return returnVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda val? 1\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "W [[ -2.22705551e-01   5.09871203e-01  -3.08710994e-01]\n",
      " [  1.94396123e-02   1.68537309e-03   3.54979410e-02]\n",
      " [  1.52104853e-02  -5.09988536e-02   3.69792779e-02]\n",
      " [  3.33126821e-01  -8.23737550e-01   5.03114208e-01]\n",
      " [ -6.03252469e-02   1.00365024e-01  -3.01069277e-02]\n",
      " [ -2.08197707e-03   6.58765086e-04   2.47278057e-03]\n",
      " [ -1.10875452e-01  -1.83361296e-02   1.53918636e-01]\n",
      " [  3.63052863e-02   1.34829884e-01  -1.90457678e-01]\n",
      " [ -3.97033194e-01   3.86804689e-01  -1.66691470e-02]\n",
      " [  3.42021018e-02   1.85745340e-02  -4.10893291e-02]\n",
      " [  2.75010396e-02  -1.12601565e-01   7.35600739e-02]\n",
      " [  4.65710098e-02  -6.29533966e-02   3.96558067e-02]\n",
      " [  2.02882110e-01   6.34188815e-02  -2.68892171e-01]\n",
      " [  5.87344535e-04  -2.60134503e-05  -5.95995159e-04]]\n",
      "23\n",
      "class1 misclassification error =  0.0\n",
      "class2 misclassification error =  11.111111111111114\n",
      "class3 misclassification error =  0.0\n",
      "total misclassification error =  4.166666666666657\n",
      "24\n",
      "error  4.166666666666657\n",
      "lambda val? 0\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "W [[ -1.55848700e+00   3.06313846e+00  -5.04651453e-01]\n",
      " [  9.34802367e-02  -1.39838902e-01   4.63586652e-02]\n",
      " [  1.67677289e-02  -5.39754327e-02   3.72077038e-02]\n",
      " [  3.49476477e-01  -8.54988951e-01   5.05512474e-01]\n",
      " [ -4.73369677e-02   7.55386964e-02  -2.82017288e-02]\n",
      " [ -7.09552190e-04  -1.96454392e-03   2.67409611e-03]\n",
      " [ -7.85682948e-02  -8.00893495e-02   1.58657644e-01]\n",
      " [  1.10390095e-02   1.83124878e-01  -1.94163887e-01]\n",
      " [ -4.32204796e-01   4.54033125e-01  -2.18283291e-02]\n",
      " [  4.94845244e-02  -1.06369129e-02  -3.88476115e-02]\n",
      " [  1.24106467e-02  -8.37571711e-02   7.13465243e-02]\n",
      " [  7.70035332e-02  -1.21123365e-01   4.41198322e-02]\n",
      " [  1.99493861e-01   6.98953182e-02  -2.69389179e-01]\n",
      " [  5.42017493e-04   6.06265093e-05  -6.02644003e-04]]\n",
      "23\n",
      "class1 misclassification error =  0.0\n",
      "class2 misclassification error =  11.111111111111114\n",
      "class3 misclassification error =  0.0\n",
      "total misclassification error =  4.166666666666657\n",
      "24\n",
      "error  4.166666666666657\n",
      "lambda val? 0.1\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "W [[ -6.86180639e-01   1.39577643e+00  -3.76696308e-01]\n",
      " [  4.51294322e-02  -4.74191984e-02   3.92662783e-02]\n",
      " [  1.57508009e-02  -5.20316350e-02   3.70585347e-02]\n",
      " [  3.38799649e-01  -8.34580825e-01   5.03946333e-01]\n",
      " [ -5.58187134e-02   9.17510517e-02  -2.94458822e-02]\n",
      " [ -1.60578784e-03  -2.51442470e-04   2.54263087e-03]\n",
      " [ -9.96658617e-02  -3.97625979e-02   1.55562926e-01]\n",
      " [  2.75386652e-02   1.51586761e-01  -1.91743618e-01]\n",
      " [ -4.09236659e-01   4.10130889e-01  -1.84592246e-02]\n",
      " [  3.95046325e-02   8.43906021e-03  -4.03115220e-02]\n",
      " [  2.22651373e-02  -1.02593447e-01   7.27920403e-02]\n",
      " [  5.71301596e-02  -8.31365871e-02   4.12046863e-02]\n",
      " [  2.01706491e-01   6.56660059e-02  -2.69064617e-01]\n",
      " [  5.71617445e-04   4.04795146e-06  -5.98302104e-04]]\n",
      "23\n",
      "class1 misclassification error =  0.0\n",
      "class2 misclassification error =  11.111111111111114\n",
      "class3 misclassification error =  0.0\n",
      "total misclassification error =  4.166666666666657\n",
      "24\n",
      "error  4.166666666666657\n",
      "lambda val? 0.3\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "W [[ -3.84431680e-01   8.19001135e-01  -3.32433955e-01]\n",
      " [  2.84038808e-02  -1.54492960e-02   3.68128738e-02]\n",
      " [  1.53990243e-02  -5.13592349e-02   3.70069340e-02]\n",
      " [  3.35106311e-01  -8.27521229e-01   5.03404572e-01]\n",
      " [ -5.87527261e-02   9.73592435e-02  -2.98762609e-02]\n",
      " [ -1.91581444e-03   3.41155038e-04   2.49715431e-03]\n",
      " [ -1.06963950e-01  -2.58127338e-02   1.54492399e-01]\n",
      " [  3.32462401e-02   1.40677070e-01  -1.90906397e-01]\n",
      " [ -4.01291501e-01   3.94944190e-01  -1.72937810e-02]\n",
      " [  3.60523798e-02   1.50378370e-02  -4.08179192e-02]\n",
      " [  2.56740110e-02  -1.09109308e-01   7.32920744e-02]\n",
      " [  5.02555453e-02  -6.99961684e-02   4.01962765e-02]\n",
      " [  2.02471887e-01   6.42029986e-02  -2.68952345e-01]\n",
      " [  5.81856686e-04  -1.55237514e-05  -5.96800150e-04]]\n",
      "23\n",
      "class1 misclassification error =  0.0\n",
      "class2 misclassification error =  11.111111111111114\n",
      "class3 misclassification error =  0.0\n",
      "total misclassification error =  4.166666666666657\n",
      "24\n",
      "error  4.166666666666657\n",
      "lambda val? 0.01\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "W [[ -1.36332674e+00   2.69010116e+00  -4.76024171e-01]\n",
      " [  8.26627577e-02  -1.19161931e-01   4.47718923e-02]\n",
      " [  1.65402126e-02  -5.35405487e-02   3.71743303e-02]\n",
      " [  3.47087761e-01  -8.50423061e-01   5.05162083e-01]\n",
      " [ -4.92345805e-02   7.91658711e-02  -2.84800820e-02]\n",
      " [ -9.10066130e-04  -1.58127338e-03   2.64468352e-03]\n",
      " [ -8.32884331e-02  -7.10670842e-02   1.57965266e-01]\n",
      " [  1.47304616e-02   1.76068885e-01  -1.93622403e-01]\n",
      " [ -4.27066157e-01   4.44210920e-01  -2.10745626e-02]\n",
      " [  4.72517328e-02  -6.36906378e-03  -3.91751308e-02]\n",
      " [  1.46153824e-02  -8.79713929e-02   7.16699282e-02]\n",
      " [  7.25572824e-02  -1.12624620e-01   4.34676294e-02]\n",
      " [  1.99988891e-01   6.89490983e-02  -2.69316565e-01]\n",
      " [  5.48639862e-04   4.79682430e-05  -6.01672594e-04]]\n",
      "23\n",
      "class1 misclassification error =  0.0\n",
      "class2 misclassification error =  11.111111111111114\n",
      "class3 misclassification error =  0.0\n",
      "total misclassification error =  4.166666666666657\n",
      "24\n",
      "error  4.166666666666657\n",
      "lambda val? 0.03\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "W [[ -1.09926961e+00   2.18537156e+00  -4.37290682e-01]\n",
      " [  6.80264151e-02  -9.11854271e-02   4.26249455e-02]\n",
      " [  1.62323768e-02  -5.29521389e-02   3.71291751e-02]\n",
      " [  3.43855762e-01  -8.44245287e-01   5.04687994e-01]\n",
      " [ -5.18021021e-02   8.40735369e-02  -2.88567015e-02]\n",
      " [ -1.18136693e-03  -1.06269794e-03   2.60488748e-03]\n",
      " [ -8.96749084e-02  -5.88597143e-02   1.57028459e-01]\n",
      " [  1.97250964e-02   1.66521936e-01  -1.92889760e-01]\n",
      " [ -4.20113438e-01   4.30921210e-01  -2.00546960e-02]\n",
      " [  4.42307051e-02  -5.94548093e-04  -3.96182733e-02]\n",
      " [  1.75984497e-02  -9.36733495e-02   7.21075025e-02]\n",
      " [  6.65413845e-02  -1.01125587e-01   4.25851813e-02]\n",
      " [  2.00658679e-01   6.76688369e-02  -2.69218317e-01]\n",
      " [  5.57600107e-04   3.08412651e-05  -6.00358251e-04]]\n",
      "23\n",
      "class1 misclassification error =  0.0\n",
      "class2 misclassification error =  11.111111111111114\n",
      "class3 misclassification error =  0.0\n",
      "total misclassification error =  4.166666666666657\n",
      "24\n",
      "error  4.166666666666657\n",
      "lambda val? 0.001\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "W [[ -1.53621532e+00   3.02056746e+00  -5.01384509e-01]\n",
      " [  9.22457465e-02  -1.37479247e-01   4.61775827e-02]\n",
      " [  1.67417647e-02  -5.39258037e-02   3.72038952e-02]\n",
      " [  3.49203877e-01  -8.54467892e-01   5.05472488e-01]\n",
      " [ -4.75535232e-02   7.59526294e-02  -2.82334944e-02]\n",
      " [ -7.32434831e-04  -1.92080510e-03   2.67073954e-03]\n",
      " [ -7.91069567e-02  -7.90597290e-02   1.58578630e-01]\n",
      " [  1.14602778e-02   1.82319648e-01  -1.94102093e-01]\n",
      " [ -4.31618375e-01   4.52912216e-01  -2.17423093e-02]\n",
      " [  4.92297183e-02  -1.01498661e-02  -3.88849880e-02]\n",
      " [  1.26622511e-02  -8.42380979e-02   7.13834312e-02]\n",
      " [  7.64961273e-02  -1.20153489e-01   4.40454029e-02]\n",
      " [  1.99550354e-01   6.97873357e-02  -2.69380893e-01]\n",
      " [  5.42773238e-04   5.91819486e-05  -6.02533145e-04]]\n",
      "23\n",
      "class1 misclassification error =  0.0\n",
      "class2 misclassification error =  11.111111111111114\n",
      "class3 misclassification error =  0.0\n",
      "total misclassification error =  4.166666666666657\n",
      "24\n",
      "error  4.166666666666657\n",
      "lambda val? 0.003\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "W [[ -1.49370468e+00   2.93931088e+00  -4.95148792e-01]\n",
      " [  8.98894371e-02  -1.32975301e-01   4.58319451e-02]\n",
      " [  1.66922061e-02  -5.38310754e-02   3.71966257e-02]\n",
      " [  3.48683556e-01  -8.53473330e-01   5.05396164e-01]\n",
      " [ -4.79668693e-02   7.67427161e-02  -2.82941265e-02]\n",
      " [ -7.76111633e-04  -1.83731948e-03   2.66433277e-03]\n",
      " [ -8.01351174e-02  -7.70944607e-02   1.58427813e-01]\n",
      " [  1.22643657e-02   1.80782682e-01  -1.93984144e-01]\n",
      " [ -4.30499054e-01   4.50772701e-01  -2.15781207e-02]\n",
      " [  4.87433621e-02  -9.22022504e-03  -3.89563296e-02]\n",
      " [  1.31424960e-02  -8.51560576e-02   7.14538764e-02]\n",
      " [  7.55276259e-02  -1.18302256e-01   4.39033373e-02]\n",
      " [  1.99658183e-01   6.95812260e-02  -2.69365075e-01]\n",
      " [  5.44215750e-04   5.64246710e-05  -6.02321549e-04]]\n",
      "23\n",
      "class1 misclassification error =  0.0\n",
      "class2 misclassification error =  11.111111111111114\n",
      "class3 misclassification error =  0.0\n",
      "total misclassification error =  4.166666666666657\n",
      "24\n",
      "error  4.166666666666657\n",
      "lambda val? 0.0001\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "W [[ -1.55622794e+00   3.05882039e+00  -5.04320079e-01]\n",
      " [  9.33550196e-02  -1.39599557e-01   4.63402976e-02]\n",
      " [  1.67650953e-02  -5.39703987e-02   3.72073175e-02]\n",
      " [  3.49448827e-01  -8.54936099e-01   5.05508418e-01]\n",
      " [ -4.73589334e-02   7.55806826e-02  -2.82049508e-02]\n",
      " [ -7.11873227e-04  -1.96010739e-03   2.67375564e-03]\n",
      " [ -7.86229324e-02  -7.99849128e-02   1.58649630e-01]\n",
      " [  1.10817397e-02   1.83043201e-01  -1.94157619e-01]\n",
      " [ -4.32145314e-01   4.53919429e-01  -2.18196039e-02]\n",
      " [  4.94586788e-02  -1.05875106e-02  -3.88514027e-02]\n",
      " [  1.24361675e-02  -8.38059525e-02   7.13502679e-02]\n",
      " [  7.69520659e-02  -1.21024989e-01   4.41122827e-02]\n",
      " [  1.99499591e-01   6.98843653e-02  -2.69388339e-01]\n",
      " [  5.42094150e-04   6.04799843e-05  -6.02632758e-04]]\n",
      "23\n",
      "class1 misclassification error =  0.0\n",
      "class2 misclassification error =  11.111111111111114\n",
      "class3 misclassification error =  0.0\n",
      "total misclassification error =  4.166666666666657\n",
      "24\n",
      "error  4.166666666666657\n",
      "lambda val? 0.0003\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "W [[ -1.55173131e+00   3.05022534e+00  -5.03660487e-01]\n",
      " [  9.31057772e-02  -1.39123145e-01   4.63037372e-02]\n",
      " [  1.67598531e-02  -5.39603787e-02   3.72065485e-02]\n",
      " [  3.49393789e-01  -8.54830898e-01   5.05500345e-01]\n",
      " [ -4.74026557e-02   7.56642553e-02  -2.82113643e-02]\n",
      " [ -7.16493210e-04  -1.95127657e-03   2.67307796e-03]\n",
      " [ -7.87316878e-02  -7.97770334e-02   1.58633677e-01]\n",
      " [  1.11667933e-02   1.82880626e-01  -1.94145143e-01]\n",
      " [ -4.32026916e-01   4.53693118e-01  -2.18022366e-02]\n",
      " [  4.94072337e-02  -1.04891764e-02  -3.88589489e-02]\n",
      " [  1.24869662e-02  -8.39030512e-02   7.13577193e-02]\n",
      " [  7.68496211e-02  -1.20829172e-01   4.40972555e-02]\n",
      " [  1.99510997e-01   6.98625638e-02  -2.69386666e-01]\n",
      " [  5.42246734e-04   6.01883289e-05  -6.02610376e-04]]\n",
      "23\n",
      "class1 misclassification error =  0.0\n",
      "class2 misclassification error =  11.111111111111114\n",
      "class3 misclassification error =  0.0\n",
      "total misclassification error =  4.166666666666657\n",
      "24\n",
      "error  4.166666666666657\n",
      "smalled index of error for lambda... 0\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#cross validation\n",
    "lambdaValues = [1, 0,.1 , .3, .01, .03, .001, .003, .0001, .0003]\n",
    "totalErrorValues = []\n",
    "lambdaIndexOfMinError = -1\n",
    "minError = 101\n",
    "i = 0\n",
    "for l in lambdaValues :\n",
    "    print(\"lambda val?\",l)\n",
    "    W=0\n",
    "    W = createWeightMatrix(inputTrain, expectedOutputTrain, l)\n",
    "    print(\"W\",W)\n",
    "    error, predictedClasses, correctPredCol = classificationTest(validateTest, validateOutputTest, W, True)\n",
    "    totalErrorValues.append(error)\n",
    "    print(\"error \",error)    \n",
    "    if(error < minError):\n",
    "        minError = error\n",
    "        lambdaIndexOfMinError = i\n",
    "    i+=1\n",
    "print(\"smalled index of error for lambda...\", lambdaIndexOfMinError)\n",
    "\n",
    "Wtest = createWeightMatrix(inputTrain, expectedOutputTrain, lambdaValues[lambdaIndexOfMinError])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJJahoIkqfX/ARe3vOl3jX26AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x296d4feb518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lambdaValues, totalErrorValues, 'o')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('total misclassification error')\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n",
      "class1 misclassification error =  2.7777777777777857\n",
      "class2 misclassification error =  18.604651162790702\n",
      "class3 misclassification error =  3.5714285714285694\n",
      "total misclassification error =  9.34579439252336\n",
      "107\n",
      "9.34579439252336\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "error, predictedClasses, correctPredictionCol = classificationTest(inputTest, expectedOutputTest, Wtest, False)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted  Predicted  Predicted  Actual  Actual  Actual  Correct\n",
       "0          1.0        0.0        0.0       1       0       0        1\n",
       "1          1.0        0.0        0.0       1       0       0        1\n",
       "2          0.0        0.0        1.0       0       0       1        1\n",
       "3          1.0        0.0        0.0       1       0       0        1\n",
       "4          0.0        1.0        0.0       0       1       0        1\n",
       "5          1.0        0.0        0.0       1       0       0        1\n",
       "6          0.0        1.0        0.0       0       1       0        1\n",
       "7          0.0        0.0        1.0       0       0       1        1\n",
       "8          0.0        1.0        0.0       0       1       0        1\n",
       "9          0.0        0.0        1.0       0       0       1        1\n",
       "10         1.0        0.0        0.0       1       0       0        1\n",
       "11         0.0        0.0        1.0       0       0       1        1\n",
       "12         1.0        0.0        0.0       1       0       0        1\n",
       "13         0.0        0.0        1.0       0       1       0        0\n",
       "14         1.0        0.0        0.0       1       0       0        1\n",
       "15         0.0        1.0        0.0       0       1       0        1\n",
       "16         0.0        1.0        0.0       0       1       0        1\n",
       "17         0.0        1.0        0.0       0       1       0        1\n",
       "18         1.0        0.0        0.0       1       0       0        1\n",
       "19         0.0        1.0        0.0       0       1       0        1\n",
       "20         1.0        0.0        0.0       1       0       0        1\n",
       "21         0.0        1.0        0.0       0       1       0        1\n",
       "22         0.0        0.0        1.0       0       1       0        0\n",
       "23         0.0        0.0        1.0       0       0       1        1\n",
       "24         0.0        0.0        1.0       0       0       1        1\n",
       "25         0.0        0.0        1.0       0       0       1        1\n",
       "26         0.0        1.0        0.0       0       1       0        1\n",
       "27         1.0        0.0        0.0       0       1       0        0\n",
       "28         0.0        1.0        0.0       0       1       0        1\n",
       "29         1.0        0.0        0.0       1       0       0        1\n",
       "..         ...        ...        ...     ...     ...     ...      ...\n",
       "77         0.0        0.0        1.0       0       0       1        1\n",
       "78         0.0        1.0        0.0       0       1       0        1\n",
       "79         0.0        0.0        1.0       0       1       0        0\n",
       "80         1.0        0.0        0.0       1       0       0        1\n",
       "81         0.0        0.0        1.0       0       1       0        0\n",
       "82         1.0        0.0        0.0       1       0       0        1\n",
       "83         1.0        0.0        0.0       1       0       0        1\n",
       "84         0.0        1.0        0.0       0       1       0        1\n",
       "85         0.0        1.0        0.0       1       0       0        0\n",
       "86         1.0        0.0        0.0       1       0       0        1\n",
       "87         0.0        0.0        1.0       0       0       1        1\n",
       "88         0.0        1.0        0.0       0       1       0        1\n",
       "89         0.0        1.0        0.0       0       1       0        1\n",
       "90         1.0        0.0        0.0       0       1       0        0\n",
       "91         1.0        0.0        0.0       1       0       0        1\n",
       "92         0.0        1.0        0.0       0       1       0        1\n",
       "93         0.0        1.0        0.0       0       1       0        1\n",
       "94         0.0        1.0        0.0       0       1       0        1\n",
       "95         0.0        0.0        1.0       0       0       1        1\n",
       "96         0.0        0.0        1.0       0       0       1        1\n",
       "97         1.0        0.0        0.0       1       0       0        1\n",
       "98         0.0        1.0        0.0       0       1       0        1\n",
       "99         0.0        0.0        1.0       0       0       1        1\n",
       "100        0.0        0.0        1.0       0       0       1        1\n",
       "101        0.0        0.0        1.0       0       1       0        0\n",
       "102        0.0        1.0        0.0       0       1       0        1\n",
       "103        1.0        0.0        0.0       1       0       0        1\n",
       "104        0.0        1.0        0.0       0       1       0        1\n",
       "105        0.0        0.0        1.0       0       0       1        1\n",
       "106        0.0        0.0        1.0       0       0       1        1\n",
       "\n",
       "[107 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = pd.DataFrame(expectedOutputTest)\n",
    "predictedDF = pd.DataFrame(predictedClasses)\n",
    "correct = pd.DataFrame(correctPredictionCol)\n",
    "frames = [predictedDF, actual, correct]\n",
    "modelTest = pd.concat(frames, axis=1)\n",
    "modelTest.columns = [\"Predicted\",\"Predicted\", \"Predicted\", \"Actual\", \"Actual\", \"Actual\", \"Correct\"]\n",
    "modelTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35,  1,  0],\n",
       "       [ 2, 35,  6],\n",
       "       [ 0,  1, 27]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualAsClassNumber = [0]*expectedOutputTest.shape[0]\n",
    "predictedAsClassNumber = [0]*expectedOutputTest.shape[0]\n",
    "for i in range(expectedOutputTest.shape[0]):\n",
    "    actualAsClassNumber[i] = expectedOutputTest[i].tolist().index(1)\n",
    "    predictedAsClassNumber[i] = predictedClasses[i].tolist().index(1.0)\n",
    "confusion_matrix(actualAsClassNumber, predictedAsClassNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.205607476636\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "expectedOutputSVM = data.loc[:,13]\n",
    "inputTrain, inputTest, expectedOutputTrain, expectedOutputTest = train_test_split(dataInputs, expectedOutputSVM, train_size = trainPercent/100, random_state=42)\n",
    "clf.fit(inputTrain, expectedOutputTrain)\n",
    "accuracy = clf.score(inputTest, expectedOutputTest)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM One vs all classifier\n",
    "clf = Pipeline([\n",
    "    ('clf', OneVsRestClassifier(LinearSVC()))])\n",
    "model = clf.fit(inputTrain, expectedOutputTrain)\n",
    "accuracy = clf.score(inputTest, expectedOutputTest)\n",
    "print(accuracy)\n",
    "svmPredicted = model.predict(inputTest)\n",
    "confusion_matrix(expectedOutputTest,svmPredicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
