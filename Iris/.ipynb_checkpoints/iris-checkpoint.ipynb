{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are we doing?\n",
    "Predict who survived (1) or died (0) based on input information.\n",
    "\n",
    "Raw data is also availble on wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle, randint\n",
    "\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting errors with sklearn? \n",
    "\n",
    "Scikit-learn requires:\n",
    "<li>Python (>= 2.6 or >= 3.3),\n",
    "<li>NumPy (>= 1.6.1),\n",
    "<li>SciPy (>= 0.9).\n",
    "\n",
    "Try:\n",
    "conda install scikit-learn\n",
    "OR\n",
    "pip install -U scikit-learn\n",
    "\n",
    "Still got probs?\n",
    "\n",
    "python -m pip install --upgrade pip\n",
    "pip install --user numpy scipy matplotlib ipython jupyter pandas sympy nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read in csv file\n",
    "data = pd.read_csv(\"iris.csv\", header=None)\n",
    "trainPercent = 33 #must be between 0 and 100\n",
    "lmbda = .00001\n",
    "numberRowsOfEachClass = 50\n",
    "data.head() #look at first 5 rows of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions\n",
    "<li>date_frame.head()\n",
    "<li>data.columns\n",
    "<li>data_frame.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Grab desired inputs to test one. Build a dataframe from them.\n",
    "dataInputs= data.loc[:,0:3]\n",
    "dataInputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Grab the expected outputs. (This is supervised learning)\n",
    "y1=[]\n",
    "y2=[]\n",
    "y3=[]\n",
    "for i in range(0,numberRowsOfEachClass):\n",
    "    y1.append([1,0,0]);#setosa\n",
    "    y2.append([0,1,0]);#versicolor\n",
    "    y3.append([0,0,1]);#virginica\n",
    "expectedOutput=np.concatenate([y1,y2,y3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breakdown the input data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Hint: use train_test_split\n",
    "inputTrain, inputTest, expectedOutputTrain, expectedOutputTest = train_test_split(dataInputs, expectedOutput, train_size = trainPercent/100, random_state = 42)\n",
    "\n",
    "#inputTest.head()\n",
    "print(inputTrain.shape)\n",
    "print(expectedOutputTrain.shape)\n",
    "print(inputTest.shape)\n",
    "print(expectedOutputTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Build our least squares classifier for 2 classes\n",
    "D = inputTrain.shape[1] + 1 #num of attributes, +1 is for the intercept (column of 1s)\n",
    "K = expectedOutput.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expectedOutputTrain = np.asarray(expectedOutputTrain)\n",
    "expectedOutputTest = np.asarray(expectedOutputTest)\n",
    "inputTrain = np.asarray(inputTrain)\n",
    "inputTest = np.asarray(inputTest)\n",
    "p = np.append(1, inputTrain[0])\n",
    "p.shape\n",
    "p.reshape(1,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "sum1=0\n",
    "sum2=0\n",
    "for xi in inputTrain:\n",
    "    xi = np.append(1, xi)\n",
    "    xi = xi.reshape(1,D)\n",
    "    yi=expectedOutputTrain[i].reshape(1,K)          \n",
    "    sum1 += np.dot(xi, xi.T) + lmbda   \n",
    "    sum2 += np.dot(xi.T, yi)    \n",
    "    i += 1\n",
    "sum1 = np.asscalar(sum1)\n",
    "print(sum1)\n",
    "print(sum2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W=sum2/sum1\n",
    "#W = np.array(W)[np.newaxis]\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#testing\n",
    "total = expectedOutputTest.shape[0]\n",
    "predicted = [0] * total\n",
    "i=0\n",
    "numCorrect=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(total):\n",
    "    x = inputTest[i]    \n",
    "    x = np.append(1,x)\n",
    "    x = x.reshape(1,D)\n",
    "    values = np.dot(W.T,x.T)\n",
    "    values = values.T\n",
    "    values = values.flatten()\n",
    "    print(values)\n",
    "    print(np.argmax(values))\n",
    "#     if values > .5:\n",
    "#         predicted[i] = 1         \n",
    "#     if predicted[i] == expectedOutputTest[i]:\n",
    "#         numCorrect+=1      \n",
    "print(numCorrect)\n",
    "accuracy=numCorrect/float(total)*100\n",
    "print(accuracy)\n",
    "print(total)\n",
    "#######################################################################################################\n",
    "#TODO: This is weird... in the values vector (wT*xT) the 3rd column always has the highest value... :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual = pd.DataFrame(expectedOutputTest)\n",
    "predictedDF = pd.DataFrame(predicted)\n",
    "frames = [predictedDF, actual]\n",
    "modelTest = pd.concat(frames, axis=1)\n",
    "modelTest.columns = [\"Predicted\", \"Actual\"]\n",
    "modelTest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
