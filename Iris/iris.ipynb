{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are we doing?\n",
    "Predict who survived (1) or died (0) based on input information.\n",
    "\n",
    "Raw data is also availble on wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from random import shuffle, randint\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting errors with sklearn? \n",
    "\n",
    "Scikit-learn requires:\n",
    "<li>Python (>= 2.6 or >= 3.3),\n",
    "<li>NumPy (>= 1.6.1),\n",
    "<li>SciPy (>= 0.9).\n",
    "\n",
    "Try:\n",
    "conda install scikit-learn\n",
    "OR\n",
    "pip install -U scikit-learn\n",
    "\n",
    "Still got probs?\n",
    "\n",
    "python -m pip install --upgrade pip\n",
    "pip install --user numpy scipy matplotlib ipython jupyter pandas sympy nose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in csv file\n",
    "data = pd.read_csv(\"iris.csv\", header=None)\n",
    "trainPercent = 50 #must be between 0 and 100\n",
    "validationPercent = 35\n",
    "numberRowsOfEachClass = 50\n",
    "data.head() #look at first 5 rows of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful functions\n",
    "<li>date_frame.head()\n",
    "<li>data.columns\n",
    "<li>data_frame.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  5.1  3.5  1.4  0.2\n",
       "1  4.9  3.0  1.4  0.2\n",
       "2  4.7  3.2  1.3  0.2\n",
       "3  4.6  3.1  1.5  0.2\n",
       "4  5.0  3.6  1.4  0.2"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grab desired inputs to test one. Build a dataframe from them.\n",
    "dataInputs= data.loc[:,0:3]\n",
    "dataInputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Grab the expected outputs. (This is supervised learning)\n",
    "y1=[]\n",
    "y2=[]\n",
    "y3=[]\n",
    "for i in range(0,numberRowsOfEachClass):\n",
    "    y1.append([1,0,0]);#setosa\n",
    "    y2.append([0,1,0]);#versicolor\n",
    "    y3.append([0,0,1]);#virginica\n",
    "expectedOutput=np.concatenate([y1,y2,y3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breakdown the input data into test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 4)\n",
      "(26, 3)\n",
      "(49, 4)\n",
      "(49, 3)\n",
      "(75, 4)\n",
      "(75, 3)\n",
      "[[0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]]\n",
      "ValidateTest [[0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "[[ 0  1  0 23]\n",
      " [ 1  0  0 29]\n",
      " [ 0  0  1 23]]\n",
      "[[ 0  1  0 11]\n",
      " [ 1  0  0  5]\n",
      " [ 0  0  1 10]]\n",
      "29\n",
      "23\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "#Hint: use train_test_split\n",
    "inputTrain, inputTest, expectedOutputTrain, expectedOutputTest = train_test_split(dataInputs, expectedOutput, train_size = trainPercent/100, random_state=42)\n",
    "validateTest, inputTrain, validateOutputTest, expectedOutputTrain = train_test_split(inputTrain, expectedOutputTrain, train_size = validationPercent/100, random_state=42)\n",
    "#inputTest.head()\n",
    "print(validateTest.shape)\n",
    "print(validateOutputTest.shape)\n",
    "print(inputTrain.shape)\n",
    "print(expectedOutputTrain.shape)\n",
    "print(inputTest.shape)\n",
    "print(expectedOutputTest.shape)\n",
    "\n",
    "def getClassCountTotals(output):\n",
    "    d = collections.OrderedDict()\n",
    "    for a in output:\n",
    "        t = tuple(a)\n",
    "        if t in d:\n",
    "            d[t] += 1\n",
    "        else:\n",
    "            d[t] = 1\n",
    "\n",
    "    result = []\n",
    "    for (key, value) in d.items():\n",
    "        result.append(list(key) + [value])\n",
    "\n",
    "    B = np.asarray(result)\n",
    "    print(B)\n",
    "    for Bi in B:\n",
    "        if Bi[0] == 1:\n",
    "            setosaTotal = Bi[3]\n",
    "        elif Bi[1] == 1:\n",
    "            versicolorTotal = Bi[3]\n",
    "        elif Bi[2] == 1:\n",
    "            virginicaTotal = Bi[3]\n",
    "    return setosaTotal, versicolorTotal, virginicaTotal\n",
    "print(expectedOutputTest)\n",
    "print(\"ValidateTest\",validateOutputTest)\n",
    "setosaTotal, versicolorTotal, virginicaTotal = getClassCountTotals(expectedOutputTest)\n",
    "validationCounts = getClassCountTotals(validateOutputTest)\n",
    "print(setosaTotal)\n",
    "print(versicolorTotal)\n",
    "print(virginicaTotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Build our least squares classifier for 2 classes\n",
    "D = inputTrain.shape[1] + 1 #num of attributes, +1 is for the intercept (column of 1s)\n",
    "K = expectedOutput.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "expectedOutputTrain = np.asarray(expectedOutputTrain)\n",
    "expectedOutputTest = np.asarray(expectedOutputTest)\n",
    "inputTrain = np.asarray(inputTrain)\n",
    "inputTest = np.asarray(inputTest)\n",
    "validateTest = np.asarray(validateTest)\n",
    "validateOutputTest = np.asarray(validateOutputTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum1 = 0\n",
    "sum2 = 0\n",
    "def createWeightMatrix(x, y, lmbda):\n",
    "    numRows = x.shape[0]\n",
    "    print(\"y\", y)\n",
    "    new_col = np.ones((numRows,1))\n",
    "    augmentedX = np.c_[new_col, x]\n",
    "    sum1 = np.dot(augmentedX.T, augmentedX) + lmbda\n",
    "    sum2 = np.dot(augmentedX.T, y)\n",
    "    W = np.dot(np.linalg.inv(sum1), sum2)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classificationTest(xTest, yTest, W, isValidating):  \n",
    "    returnVals = []\n",
    "    total = yTest.shape[0]\n",
    "    predicted = np.zeros((total, K))\n",
    "    i=0\n",
    "    setosaCorrect=versicolorCorrect=virginicaCorrect=totalCorrect=0\n",
    "    correctPredictionCol = [0]*total\n",
    "    for i in range(total):      \n",
    "        x = xTest[i]        \n",
    "        x = np.append(1,x)         \n",
    "        x = x.reshape(1,D)        \n",
    "        values = np.dot(W.T,x.T)\n",
    "        values = values.T\n",
    "        values = values.flatten()\n",
    "        maxIndex = np.argmax(values)\n",
    "        if yTest[i][maxIndex] == 1:\n",
    "            if maxIndex == 0:\n",
    "                setosaCorrect += 1\n",
    "            elif maxIndex == 1:\n",
    "                versicolorCorrect += 1\n",
    "            elif maxIndex == 2:\n",
    "                virginicaCorrect += 1\n",
    "            correctPredictionCol[i] = 1\n",
    "        predicted[i][maxIndex] = 1\n",
    "    totalCorrect = setosaCorrect + versicolorCorrect + virginicaCorrect\n",
    "    print(totalCorrect)\n",
    "    totalAccuracy=totalCorrect/float(total)*100\n",
    "    if isValidating == False:\n",
    "        setosaAccuracy = setosaCorrect/float(setosaTotal)*100\n",
    "        versicolorAccuracy = versicolorCorrect/float(versicolorTotal)*100\n",
    "        virginicaAccuracy = virginicaCorrect/float(virginicaTotal)*100\n",
    "        print(\"setosa misclassification error = \", 100 - setosaAccuracy)\n",
    "        print(\"versicolor misclassification error = \", 100 - versicolorAccuracy)\n",
    "        print(\"virginica misclassification error = \", 100 - virginicaAccuracy)\n",
    "    else:\n",
    "        setosaAccuracy = setosaCorrect/float(validationCounts[0])*100\n",
    "        versicolorAccuracy = versicolorCorrect/float(validationCounts[1])*100\n",
    "        virginicaAccuracy = virginicaCorrect/float(validationCounts[2])*100\n",
    "        print(\"setosa misclassification error = \", 100 - setosaAccuracy)\n",
    "        print(\"versicolor misclassification error = \", 100 - versicolorAccuracy)\n",
    "        print(\"virginica misclassification error = \", 100 - virginicaAccuracy)\n",
    "    print(\"total misclassification error = \", 100 - totalAccuracy)\n",
    "    print(total)\n",
    "    returnVals.append(100-totalAccuracy)\n",
    "    returnVals.append(predicted)\n",
    "    returnVals.append(correctPredictionCol)\n",
    "    return returnVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda val? 1\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "W [[-0.04112579  1.17726214 -0.89333206]\n",
      " [ 0.12691708 -0.02285663 -0.00218325]\n",
      " [ 0.22235314 -0.36284261  0.20948297]\n",
      " [-0.26527902  0.31666948 -0.00923328]\n",
      " [-0.0359417  -0.68006213  0.53933641]]\n",
      "20\n",
      "setosa misclassification error =  0.0\n",
      "versicolor misclassification error =  36.36363636363637\n",
      "virginica misclassification error =  20.0\n",
      "total misclassification error =  23.076923076923066\n",
      "26\n",
      "error  23.076923076923066\n",
      "lambda val? 0\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "W [[-0.02234617  2.3386146  -1.31626843]\n",
      " [ 0.12439037 -0.17911126  0.05472089]\n",
      " [ 0.220642   -0.46866172  0.24801972]\n",
      " [-0.26632458  0.2520107   0.01431388]\n",
      " [-0.03156008 -0.40909765  0.44065773]]\n",
      "20\n",
      "setosa misclassification error =  0.0\n",
      "versicolor misclassification error =  36.36363636363637\n",
      "virginica misclassification error =  20.0\n",
      "total misclassification error =  23.076923076923066\n",
      "26\n",
      "error  23.076923076923066\n",
      "lambda val? 0.1\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "W [[-0.02769271  2.00797883 -1.19585891]\n",
      " [ 0.12510972 -0.13462574  0.03852034]\n",
      " [ 0.22112916 -0.43853513  0.23704835]\n",
      " [-0.26602691  0.27041898  0.00761003]\n",
      " [-0.03280752 -0.48624094  0.46875144]]\n",
      "20\n",
      "setosa misclassification error =  0.0\n",
      "versicolor misclassification error =  36.36363636363637\n",
      "virginica misclassification error =  20.0\n",
      "total misclassification error =  23.076923076923066\n",
      "26\n",
      "error  23.076923076923066\n",
      "lambda val? 0.3\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "W [[ -3.37182158e-02   1.63535470e+00  -1.06015825e+00]\n",
      " [  1.25920427e-01  -8.44908771e-02   2.02624434e-02]\n",
      " [  2.21678183e-01  -4.04582688e-01   2.24683696e-01]\n",
      " [ -2.65691438e-01   2.91164988e-01   5.48417947e-05]\n",
      " [ -3.42133792e-02  -5.73180874e-01   5.00412851e-01]]\n",
      "19\n",
      "setosa misclassification error =  0.0\n",
      "versicolor misclassification error =  36.36363636363637\n",
      "virginica misclassification error =  30.0\n",
      "total misclassification error =  26.923076923076934\n",
      "26\n",
      "error  26.923076923076934\n",
      "lambda val? 0.01\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "W [[-0.02300195  2.29806078 -1.30149971]\n",
      " [ 0.1244786  -0.17365493  0.05273383]\n",
      " [ 0.22070175 -0.46496657  0.24667404]\n",
      " [-0.26628807  0.25426855  0.01349163]\n",
      " [-0.03171308 -0.41855959  0.44410353]]\n",
      "20\n",
      "setosa misclassification error =  0.0\n",
      "versicolor misclassification error =  36.36363636363637\n",
      "virginica misclassification error =  20.0\n",
      "total misclassification error =  23.076923076923066\n",
      "26\n",
      "error  23.076923076923066\n",
      "lambda val? 0.03\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "W [[-0.0242192   2.2227843  -1.27408585]\n",
      " [ 0.12464238 -0.16352683  0.04904542]\n",
      " [ 0.22081266 -0.45810759  0.24417617]\n",
      " [-0.2662203   0.2584596   0.01196535]\n",
      " [-0.03199709 -0.43612295  0.45049968]]\n",
      "20\n",
      "setosa misclassification error =  0.0\n",
      "versicolor misclassification error =  36.36363636363637\n",
      "virginica misclassification error =  20.0\n",
      "total misclassification error =  23.076923076923066\n",
      "26\n",
      "error  23.076923076923066\n",
      "lambda val? 0.001\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "W [[-0.02241327  2.33446522 -1.31475733]\n",
      " [ 0.1243994  -0.17855298  0.05451758]\n",
      " [ 0.22064811 -0.46828364  0.24788204]\n",
      " [-0.26632085  0.25224172  0.01422975]\n",
      " [-0.03157573 -0.41006578  0.44101029]]\n",
      "20\n",
      "setosa misclassification error =  0.0\n",
      "versicolor misclassification error =  36.36363636363637\n",
      "virginica misclassification error =  20.0\n",
      "total misclassification error =  23.076923076923066\n",
      "26\n",
      "error  23.076923076923066\n",
      "lambda val? 0.003\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "W [[-0.02254643  2.32623024 -1.31175835]\n",
      " [ 0.12441732 -0.177445    0.05411408]\n",
      " [ 0.22066024 -0.46753329  0.24760878]\n",
      " [-0.26631343  0.2527002   0.01406278]\n",
      " [-0.0316068  -0.41198714  0.44171001]]\n",
      "20\n",
      "setosa misclassification error =  0.0\n",
      "versicolor misclassification error =  36.36363636363637\n",
      "virginica misclassification error =  20.0\n",
      "total misclassification error =  23.076923076923066\n",
      "26\n",
      "error  23.076923076923066\n",
      "lambda val? 0.0001\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "W [[-0.0223529   2.3381987  -1.31611697]\n",
      " [ 0.12439128 -0.1790553   0.05470051]\n",
      " [ 0.22064261 -0.46862382  0.24800592]\n",
      " [-0.26632421  0.25203385  0.01430545]\n",
      " [-0.03156165 -0.40919469  0.44069306]]\n",
      "20\n",
      "setosa misclassification error =  0.0\n",
      "versicolor misclassification error =  36.36363636363637\n",
      "virginica misclassification error =  20.0\n",
      "total misclassification error =  23.076923076923066\n",
      "26\n",
      "error  23.076923076923066\n",
      "lambda val? 0.0003\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "W [[-0.02236634  2.33736754 -1.31581428]\n",
      " [ 0.12439308 -0.17894347  0.05465979]\n",
      " [ 0.22064383 -0.46854809  0.24797834]\n",
      " [-0.26632346  0.25208013  0.0142886 ]\n",
      " [-0.03156478 -0.40938861  0.44076369]]\n",
      "20\n",
      "setosa misclassification error =  0.0\n",
      "versicolor misclassification error =  36.36363636363637\n",
      "virginica misclassification error =  20.0\n",
      "total misclassification error =  23.076923076923066\n",
      "26\n",
      "error  23.076923076923066\n",
      "smalled index of error for lambda... 0\n",
      "y [[0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "#cross validation\n",
    "lambdaValues = [1, 0,.1 , .3, .01, .03, .001, .003, .0001, .0003]\n",
    "totalErrorValues  = []\n",
    "lambdaIndexOfMinError = -1\n",
    "minError = 101\n",
    "i = 0\n",
    "for l in lambdaValues :\n",
    "    print(\"lambda val?\",l)\n",
    "    W=0\n",
    "    W = createWeightMatrix(inputTrain, expectedOutputTrain, l)\n",
    "    print(\"W\",W)\n",
    "    error, predictedClasses, correctPredCol = classificationTest(validateTest, validateOutputTest, W, True)\n",
    "    totalErrorValues.append(error)\n",
    "    print(\"error \",error)    \n",
    "    if(error < minError):\n",
    "        minError = error\n",
    "        lambdaIndexOfMinError = i\n",
    "    i+=1\n",
    "print(\"smalled index of error for lambda...\", lambdaIndexOfMinError)\n",
    "Wtest = createWeightMatrix(inputTrain, expectedOutputTrain, lambdaValues[lambdaIndexOfMinError])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHfVJREFUeJzt3X+4XVV95/H3xxCGNAEjcqEmJCY4kJaOQvSC2FAfwxSB\njE8DalWqaK2aasUJSlFk5gH7WFsrJY6O1iEK/TENUloCRYtE0AhD1ZibGAhJoFIkkh9KKEKohh9J\nPvPH3rceLvfHusnd556b+3k9z3nO2Wvvtc93PYHzvXuvtdeSbSIiIobyvNEOICIixoYkjIiIKJKE\nERERRZIwIiKiSBJGREQUScKIiIgiSRgREVEkCSMiIookYURERJGDRjuAkXTEEUd41qxZox1GRMSY\nsWbNmkdsd5Uce0AljFmzZtHT0zPaYUREjBmSNpcem1tSERFRpLGEIWmGpJWSNkraIGlxXf53ktbV\nrwclrRug/pmS7pN0v6SLm4ozIiLKNHlLajdwoe21kg4F1ki61fabew+QdAXweN+KkiYAnwdOB7YA\nqyXdZHtjg/FGRMQgGrvCsL3d9tr68xPAJmB6735JAt4EfLmf6icD99t+wPbTwLXAwqZijYiIobWl\nD0PSLGAusKql+DeAn9j+QT9VpgMPtWxvoSXZ9Dn3Ikk9knp27NgxMgFHRMRzND5KStIU4HrgAts7\nW3adS/9XF8NieymwFKC7uzurQXWwG7+/lctX3Me2x3YxbeokLjpjDmfP7ffvgIjoQI0mDEkTqZLF\nMtvLW8oPAl4PvGKAqluBGS3bR9dlMUbd+P2tfHT5enY9sweArY/t4qPL1wMkaUSMEU2OkhJwFbDJ\n9pI+u38TuNf2lgGqrwaOlTRb0sHAW4Cbmoo1mnf5ivv+I1n02vXMHi5fcd8oRRQRw9VkH8Y84Dzg\ntJZhtAvqfW+hz+0oSdMk3QxgezdwPrCCqrP8OtsbGow1GrbtsV3DKo+IztPYLSnbdwIaYN/v9lO2\nDVjQsn0zcHNT8UV7TZs6ia39JIdpUyeNQjQRsS/ypHe0xUVnzGHSxAnPKps0cQIXnTFnlCKKiOE6\noOaSis7V27GdUVIRY1cSRrTN2XOnJ0FEjGG5JRUREUWSMCIiokgSRkREFEnCiIiIIkkYERFRJAkj\nIiKKJGFERESRJIyIiCiShBEREUWSMCIiokgSRkREFEnCiIiIIkkYERFRpMklWmdIWilpo6QNkha3\n7PuApHvr8k8NUP9BSevrlfp6moozIiLKNDm9+W7gQttrJR0KrJF0K3AUsBA4wfZTko4c5BzzbT/S\nYIwREVGoySVatwPb689PSNoETAfeA3zS9lP1voebiiEiIkZOW/owJM0C5gKrgOOA35C0StLtkk4a\noJqB2yStkbSoHXFGRMTAGl9xT9IU4HrgAts7JR0EHA6cApwEXCfpGNvuU/VU21vrW1a3SrrX9h39\nnH8RsAhg5syZjbYlImI8a/QKQ9JEqmSxzPbyungLsNyV7wF7gSP61rW9tX5/GLgBOLm/77C91Ha3\n7e6urq4mmhERETQ7SkrAVcAm20tadt0IzK+POQ44GHikT93JdUc5kiYDrwXuaSrWiIgYWpO3pOYB\n5wHrJa2ryy4BrgaulnQP8DTwDtuWNA34ku0FVCOpbqhyDgcB19i+pcFYIyJiCE2OkroT0AC739bP\n8duABfXnB4ATmootIiKGL096R0REkSSMiIgokoQRERFFkjAiIqJIEkZERBQZNGFIep6kN7UrmIiI\n6FyDJgzbe4EPtymWiIjoYCW3pG6T9If1+haH974ajywiIjpKyYN7b67f399SZuCYkQ8nIiI61ZAJ\nw/bsdgQSERGdbciEUc84+z7g1XXRt4ArbT/TYFwREdFhSm5JfQGYCPxFvX1eXfbupoKKiIjOU5Iw\nTrLdOhHgNyXd1VRAERHRmUpGSe2R9JLeDUnHAHuaCykiIjpRyRXGRcBKSQ9QTVf+YuCdjUYVEREd\nZ9CEIel5wC7gWGBOXXyf7aeaDiwiIjrLoAnD9l5Jn7c9F7i7TTFFREQHKunD+IakN9RrdBernwxf\nKWmjpA2SFrfs+4Cke+vyTw1Q/0xJ90m6X9LFw/nuiIgYeSV9GL8PfAjYLelJqn4M2z5siHq7gQtt\nr5V0KLBG0q1U63UvBE6w/ZSkI/tWlDQB+DxwOrAFWC3pJtsbi1sWEREjaqg+DAG/ZvtHwz2x7e3A\n9vrzE5I2AdOB9wCf7O0Hsf1wP9VPBu6v1/ZG0rVUSSYJIyJilAw1W62Bf9rfL5E0C5gLrAKOA35D\n0ipJt0s6qZ8q04GHWra31GURETFKSvow1g7wo15E0hTgeuAC2zuprmoOB06hGrJ73XD7R/qcf5Gk\nHkk9O3bs2NfTRETEEEoSxiuB70j6V0l3S1ovqWjEVD0P1fXAMtvL6+ItwHJXvgfsBY7oU3UrMKNl\n++i67DlsL7Xdbbu7q6urJKyIiNgHJZ3eZ+zLieurhquATbaXtOy6EZhP9TDgccDBwCN9qq8GjpU0\nmypRvAX4nX2JIyIiRsaQVxi2N1P9tX9a/fnnJfWAeVQTFZ4maV39WgBcDRwj6R7gWuAdti1pmqSb\n6+/cDZwPrAA2AdfZ3rAP7YuIiBGiql97kAOky4BuYI7t4yRNA/7e9rx2BDgc3d3d7unpGe0wIiLG\nDElrbHeXHFtypXAO8FvAzwBsbwMO3ffwIiJiLCpJGE/Xw2sNIGlysyFFREQnKkkY10m6Epgq6T3A\nbcAXmw0rIiI6Tcma3n8u6XRgJ9WMtZfavrXxyCIioqOUDKulThBJEhER41jJLamIiIgkjIiIKJOE\nERERRYbsw5A0D/gY1VreB/GL9TCOaTa0iIjoJCWd3lcBHwTWAHuaDSciIjpVScJ43PbXGo8kIiI6\nWknCWCnpcmA58FRvoe21jUUVEREdpyRhvLJ+b52cysBpIx9ORER0qpInvee3I5CIiOhsQw6rlfR8\nSUt6l0GVdIWk57cjuIiI6Bwlz2FcDTwBvKl+7QT+ssmgIiKi85T0YbzE9htatv9I0rqmAoqIiM5U\ncoWxS9KpvRv1g3y7hqokaYaklZI2StogaXFd/jFJW/ss29pf/Qclra+PyTJ6ERGjrOQK433AX9f9\nFgIeBX63oN5u4ELbayUdCqyR1Dvj7adt/3nBOebbfqTguIiIaFjJKKl1wAmSDqu3d5ac2PZ2YHv9\n+QlJm4Dp+xFrRESMogEThqS32f5bSR/qUw6A7SWlXyJpFjAXWAXMAz4g6e1AD9VVyE/7qWbgNkl7\ngCttLx3g3IuARQAzZ84sDSkiIoZpsD6M3rW7D+3nNaX0CyRNAa4HLqivTr4AHAOcSHUFcsUAVU+1\nfSJwFvB+Sa/u7yDbS2132+7u6uoqDSsiIoZpwCsM21fWH2+z/c+t++qO7yFJmkiVLJbZXl6f9yct\n+78IfHWA799avz8s6QbgZOCOku+NiIiRVzJK6n8Xlj2LqntXVwGbWm9fSXpRy2HnAPf0U3dy3VGO\npMnAa/s7LiIi2mewPoxXAb8OdPXpxzgMmFBw7nnAecD6luc2LgHOlXQiVR/Fg8Dv1983DfiS7QXA\nUcANdX/JQcA1tm8ZRrsiImKEDTZK6mCqvoqDqPoteu0E3jjUiW3fSTUMt6+bBzh+G7Cg/vwAcMJQ\n3xEREe0zWB/G7cDtkv7K9uY2xhQRER2o5MG9n9frYfwacEhvoe1Mbx4RMY6UdHovA+4FZgN/RNXv\nsLrBmCIiogOVJIwX2r4KeMb27bZ/jyyeFBEx7pTcknqmft8u6b8B24DDmwspIiI6UUnC+ON64sEL\nqZ6/OAz4YKNRRURExymZfLD3SezHgSzXGhExTpUs0frXkqa2bL9A0tXNhhUREZ2mpNP7ZbYf692o\nZ5ad21xIERHRiUoSxvMkvaB3Q9LhlPV9RETEAaTkh/8K4DuS/p5qqo83Ap9oNKqIiOg4JZ3ef1Ov\nqd377MXrbW9sNqyIiOg0g81We5jtnfUtqB8D17TsO9z2o+0IMCIiOsNgVxjXAK8D1lBNRd5L9fYx\nDcYVEREdZrCE8cn6/VdtP9mOYCIionMNNkrqM/X7t9sRSEREdLbBrjCekbQUOFrSZ/vutP3fBzux\npBnA31Ctnmdgqe3PSPoY8B5gR33oJbafs6iSpDOpktYEqpX4Ptn3mIiIaJ/BEsbrgN8EzqDqxxiu\n3cCFttfW63OvkXRrve/Ttv98oIqSJgCfB04HtgCrJd2U0VkREaNnsBX3HgGulbTJ9l3DPbHt7cD2\n+vMTkjYB0wurnwzcXy/ViqRrgYVAEkZExCgZbFjth21/Cni3JPfdP9QtqT7nmkU1ncgqYB7wAUlv\nB3qorkJ+2qfKdOChlu0twCtLvy8iIkbeYJ3em+r3HqpbUn1fRSRNAa4HLrC9E/gC1ZDcE6muQK4Y\nftjPOv8iST2Senbs2DF0hYiI2CeD3ZL6Sv3+171lkp4HTKl/+IckaSJVslhme3l9vp+07P8i8NV+\nqm4FZrRsH12X9RfnUmApQHd393OuhCIiYmSUTG9+jaTDJE0G7gE2SrqooJ6Aq4BNtpe0lL+o5bBz\n6nP2tRo4VtJsSQcDbwFuGuo7IyKiOSWz1R5fX1GcDXwNmA2cV1BvXn3caZLW1a8FwKckrZd0N9WC\nTB8EkDRN0s0AtncD5wMrqG6NXWd7wzDbFhERI6hkttqJ9a2ls4HP2X6mv07wvmzfSTWNSF/Peeai\nPn4bsKBl++aBjo2IiPYrucK4EngQmAzcIenFQFEfRkREHDhKpjf/LND6pPdmSVnbOyJinCnp9F5c\nd3pL0lWS1vKLtTEiImKcKLkl9Xt1p/drgRdQdWRnXqeIiHGmJGH0dlwvAP5vPVqpv87siIg4gJUk\njDWSvk6VMFbUEwnubTasiIjoNCXDat9FNY3HA7Z/LumFwDubDSsiIjpNySipvZJ+CBwn6ZA2xBQR\nER1oyIQh6d3AYqr5nNYBpwDfISOlIiLGlZI+jMXAScBm2/Oppil/rNGoIiKi45QkjCdtPwkg6T/Z\nvheY02xYERHRaUo6vbdImgrcCNwq6afA5mbDioiITlPS6X1O/fFjklYCzwduaTSqiIjoOIMt0Xp4\nP8Xr6/cpwKONRBQRER1psCuMNYB59lPdvdumWmY1IiLGicGWaJ3dzkAiIqKzlcxWe46k57dsT5V0\ndrNhRUREpykZVnuZ7cd7N2w/Blw2VCVJMyStlLRR0gZJi/vsv1CSJR0xQP0H66Vc10nqKYgzIiIa\nVDKstr+kUlJvN3Ch7bX1hIVrJN1qe6OkGVTTpf9oiHPMt/1IwXdFRETDSq4weiQtkfSS+vVpqg7x\nQdnebntt/fkJYBMwvd79aeDDVJ3nERExBpQkjA8ATwN/V7+eBN4/nC+RNItqSpFVkhYCW23fNUQ1\nA7dJWiNp0XC+LyIiRl7Jg3s/Ay4GkDQBmFyXFZE0BbgeuIDqNtUlVLejhnKq7a2SjqR6wvxe23f0\nc/5FwCKAmTNnloYVERHDVDJK6pp6Te/JVA/ubZR0UcnJJU2kShbLbC8HXgLMBu6S9CDVDLhrJf1y\n37q2t9bvDwM3ACf39x22l9rutt3d1dVVElZEROyDkltSx9drep8NfI3qB/+8oSpJEnAVsMn2EgDb\n620faXuW7VnAFuDltn/cp+7kuqOcOlG9FrinvFkRETHSShLGxPpK4WzgJtvPUNZZPY8qsZxWD41d\nJ2nBQAdLmibp5nrzKOBOSXcB3wP+yXbmr4qIGEUlw2OvBB4E7gLukPRiYOdQlWzfybOnFenvmFkt\nn7dRrRuO7QeAEwpii4iINinp9P4s8NmWos2S5jcXUkREdKLBZqt9m+2/lfShAQ5Z0lBMERHRgQa7\nwphcvx/ajkAiIqKzDTZb7ZX1+x+1L5yIiOhUQ/ZhSJpN9bT3rNbjbf9Wc2FFRESnKRkldSPV8xRf\nAfY2G05ERHSqkoTxZD1SKiIixrGShPEZSZcBXwee6i3snYk2IiLGh5KE8VLqJ7b5xS0p19sRETFO\nlCSM3waOsf1008FERETnKplL6h5gatOBREREZyu5wpgK3CtpNc/uw8iw2oiIcaQkYVzWeBQREdHx\nSiYfvL0dgURERGcr6cOIiIhIwoiIiDJJGBERUWTAhCFpvaS7+3mtl3T3UCeWNEPSSkkbJW2QtLjP\n/gslWdIRA9Q/U9J9ku6XdPHwmxYRESNpsE7v1+3nuXcDF9peK+lQYI2kW21vlDQDeC3wo/4qSpoA\nfB44HdgCrJZ0k+2N+xlTRETso8HWw9i8Pye2vR3YXn9+QtImYDqwEfg08GHgHweofjJwf722N5Ku\nBRbWdSMiYhQM2Ych6RRJqyX9u6SnJe2RtHM4XyJpFjAXWCVpIbDV9l2DVJkOPNSyvaUu6+/ciyT1\nSOrZsWPHcMKKiIhhKOn0/hxwLvADYBLwbqrbRUUkTQGuBy6guk11CXDpsCMdgO2ltrttd3d1dY3U\naSMioo+iUVK27wcm2N5j+y+BM0vqSZpIlSyW2V4OvASYDdwl6UHgaGCtpF/uU3UrMKNl++i6LCIi\nRknJ1CA/l3QwsE7Sp6j6JUpuZYlqpb5NtpcA2F4PHNlyzINAt+1H+lRfDRxbLw+7FXgL8DsFsUZE\nRENKrjDOq487H/gZ1V/+ry+oN6+ue5qkdfVrwUAHS5om6WYA27vr71sBbAKus72h4DsjIqIhsj34\nAdJi258ZqqwTdHd3u6enZ7TDiIgYMyStsd1dcmzJFcY7+in73WFFFBERY96AfRiSzqXqN5gt6aaW\nXYcBjzYdWEREdJbBOr2/TdXBfQRwRUv5E8CQU4NERMSBZagnvTcDr5J0FHBSvWtT3SkdERHjSMnw\n2N8Gvgf8NvAmqqe139h0YBER0VlKnsP4n8BJth8GkNQF3Ab8Q5OBRUREZykZJfW83mRR+7fCehER\ncQApucK4RdIK4Mv19puBrzUXUkREdKIhE4btiyS9Hji1Llpq+4Zmw4qIiE4zZMKQ9Ge2PwIs76cs\nIiLGiZK+iNP7KTtrpAOJiIjONtiT3u8D/gA4ps8a3ocC/9x0YBER0VkGuyV1DVXn9p8CF7eUP2E7\nU4NERIwzgz3p/TjwONVqexERMc7leYqIiCiShBEREUWSMCIiokhjCUPSDEkrJW2UtEHS4rr845Lu\nrpds/bqkaQPUf1DS+vq4LKMXETHKmrzC2A1caPt44BTg/ZKOBy63/TLbJwJfBS4d5BzzbZ9Yunxg\nREQ0p7GEYXu77bX15yeATcB02ztbDpsMDL6oeEREdISSyQf3m6RZwFxgVb39CeDtVMN25w9QzcBt\nkvYAV9peOsC5FwGLAGbOnDmicUdExC803uktaQpwPXBB79WF7f9hewawDDh/gKqn1retzqK6nfXq\n/g6yvdR2t+3urq6uBloQERHQcMKQNJEqWSyzvbyfQ5YBb+ivru2t9fvDwA3AyU3FGRERQ2tylJSA\nq6jWAF/SUn5sy2ELgXv7qTtZ0qG9n4HXAvc0FWtERAytyT6MecB5wHpJ6+qyS4B3SZoD7AU2A+8F\nqIfXfsn2AuAo4IYq53AQcI3tWxqMNSIihtBYwrB9J6B+dt08wPHbgAX15weAE5qKLSIihi9PekdE\nRJEkjIiIKJKEERERRZIwIiKiSBJGREQUScKIiIgiSRgREVEkCSMiIookYURERJEkjIiIKJKEERER\nRZIwIiKiSBJGREQUacsSrZ3s9CXf4gcP/+w55dOnTuKiM+Zw9tzp3Pj9rVy+4j62PbaLaS3l+6OJ\nc0bE+NLu35FxnTAGShYAWx/bxUeXr6dn86Ncv2Yru57Z86xyYJ//YW78/lY+unz9iJ4zIsaX0fgd\nGde3pAZKFr12PbOHL6966D/+QVrLL19x3z5/7+Ur7hvxc0bE+DIavyNNLtE6Q9JKSRslbZC0uC7/\nuKS7Ja2T9PV6pb3+6p8p6T5J90u6uKk4h7LH7rd822O79vmcA9Xdn3NGxPgyGr8jTV5h7AYutH08\ncArwfknHA5fbfpntE4GvApf2rShpAvB54CzgeODcum7bTVB/iwbCtKmT9vmcA9Xdn3NGxPgyGr8j\njSUM29ttr60/PwFsAqbb3tly2GSgvz/hTwbut/2A7aeBa4GFIx3jsUdOHnT/pIkTOPeVM5g0ccJz\nyi86Y84+f+9FZ8wZ8XNGxPgyGr8jbenDkDQLmAusqrc/Iekh4K30c4UBTAceatneUpeNqFs/9JoB\nk8b0qZP409e/lD8++6X86etfyvSpk1BL+f50Kp09d/qInzMixpfR+B2RB7hHP2JfIE0Bbgc+YXt5\nn30fBQ6xfVmf8jcCZ9p+d719HvBK2+f3c/5FwCKAmTNnvmLz5s3NNCQi4gAkaY3t7pJjG73CkDQR\nuB5Y1jdZ1JYBb+infCswo2X76LrsOWwvtd1tu7urq2t/Q46IiAE0OUpKwFXAJttLWsqPbTlsIXBv\nP9VXA8dKmi3pYOAtwE1NxRoREUNr8sG9ecB5wHpJ6+qyS4B3SZoD7AU2A+8FqIfXfsn2Atu7JZ0P\nrAAmAFfb3tBgrBERMYTGEobtO4H+xqTePMDx24AFLds3D3RsRES037h+0jsiIso1PkqqnSTtoLrN\ntS+OAB4ZwXDGgrT5wDfe2gtp83C92HbRiKEDKmHsD0k9pUPLDhRp84FvvLUX0uYm5ZZUREQUScKI\niIgiSRi/sHS0AxgFafOBb7y1F9LmxqQPIyIiiuQKIyIiioyrhDHUokyqfLbef7ekl49GnCOpoM1v\nrdu6XtK3JZ0wGnGOpNLFtySdJGl3PdnlmFbSZkmvqRcu2yDp9nbHONIK/tt+vqSvSLqrbvM7RyPO\nkSLpakkPS7pngP3N/37ZHhcvqilG/hU4BjgYuAs4vs8xC4CvUT2hfgqwarTjbkObfx14Qf35rPHQ\n5pbjvkk1m8AbRzvuNvw7TwU2AjPr7SNHO+42tPkS4M/qz13Ao8DBox37frT51cDLgXsG2N/479d4\nusIoWZRpIfA3rnwXmCrpRe0OdAQN2Wbb37b903rzu1QzA49lpYtvfYBqJuWH2xlcQ0ra/DvActs/\nArA91ttd0mYDh9YToU6hShi72xvmyLF9B1UbBtL479d4ShglizK1ZeGmNhpue95F9RfKWDZkmyVN\nB84BvtDGuJpU8u98HPACSd+StEbS29sWXTNK2vw54FeBbcB6YLHtve0Jb1Q0/vvV5Gy1MYZImk+V\nME4d7Vja4H8BH7G9VwOs2X4AOgh4BfBfgUnAdyR91/a/jG5YjToDWAecBrwEuFXS//Ozl4mOYRhP\nCaNkUabihZvGiKL2SHoZ8CXgLNv/1qbYmlLS5m7g2jpZHAEskLTb9o3tCXHElbR5C/Bvtn8G/EzS\nHcAJwFhNGCVtfifwSVc3+O+X9EPgV4DvtSfEtmv892s83ZIqWZTpJuDt9WiDU4DHbW9vd6AjaMg2\nS5oJLAfOO0D+2hyyzbZn255lexbwD8AfjOFkAWX/bf8jcKqkgyT9EvBKYFOb4xxJJW3+EdUVFZKO\nAuYAD7Q1yvZq/Pdr3FxheIBFmSS9t97/f6hGzCwA7gd+TvUXyphV2OZLgRcCf1H/xb3bY3jitsI2\nH1BK2mx7k6RbgLupFi/7ku1+h2eOBYX/zh8H/krSeqqRQx+xPWZnsZX0ZeA1wBGStgCXAROhfb9f\nedI7IiKKjKdbUhERsR+SMCIiokgSRkREFEnCiIiIIkkYERFRJAkjYhCS/n2EzvMxSX9YcNxfHQiz\n58aBKQkjIiKKJGFEFJA0RdI3JK2t1w5ZWJfPknRvfWXwL5KWSfpNSf8s6QeSTm45zQmSvlOXv6eu\nL0mfq9d1uA04suU7L5W0WtI9kpZqHE18FZ0pCSOizJPAObZfDswHrmj5Af/PwBVU8xT9CtVU4qcC\nf0i1JkOvl1FNhPcq4FJJ06hmzZ0DHA+8nWp9kl6fs32S7f9CNWHg6xpqW0SRcTM1SMR+EvAnkl5N\nNbXGdOCoet8Pba8HkLQB+IZt11NSzGo5xz/a3gXskrSSak2HVwNftr0H2Cbpmy3Hz5f0YeCXgMOB\nDcBXGmthxBCSMCLKvJVq1bZX2H5G0oPAIfW+p1qO29uyvZdn/z/Wdx6eAeflkXQI8BdAt+2HJH2s\n5fsiRkVuSUWUeT7wcJ0s5gMv3odzLJR0iKQXUk0itxq4A3izpAn16mjz62N7k8MjkqYAGTkVoy5X\nGBFllgFfqW8z9QD37sM57gZWUq3B8XHb2yTdQNWvsZFqOu7vANh+TNIXgXuAH1Mll4hRldlqIyKi\nSG5JRUREkSSMiIgokoQRERFFkjAiIqJIEkZERBRJwoiIiCJJGBERUSQJIyIiivx/8db6kK+Jj98A\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a56e46cd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lambdaValues, totalErrorValues, 'o')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('total misclassification error')\n",
    "plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "setosa misclassification error =  0.0\n",
      "versicolor misclassification error =  39.13043478260869\n",
      "virginica misclassification error =  13.043478260869563\n",
      "total misclassification error =  16.0\n",
      "75\n",
      "16.0\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "error, predictedClasses, correctPredictionCol = classificationTest(inputTest, expectedOutputTest, Wtest, False)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted  Predicted  Predicted  Actual  Actual  Actual  Correct\n",
       "0         0.0        1.0        0.0       0       1       0        1\n",
       "1         1.0        0.0        0.0       1       0       0        1\n",
       "2         0.0        0.0        1.0       0       0       1        1\n",
       "3         0.0        0.0        1.0       0       1       0        0\n",
       "4         0.0        1.0        0.0       0       1       0        1\n",
       "5         1.0        0.0        0.0       1       0       0        1\n",
       "6         0.0        0.0        1.0       0       1       0        0\n",
       "7         0.0        0.0        1.0       0       0       1        1\n",
       "8         0.0        1.0        0.0       0       1       0        1\n",
       "9         0.0        1.0        0.0       0       1       0        1\n",
       "10        0.0        0.0        1.0       0       0       1        1\n",
       "11        1.0        0.0        0.0       1       0       0        1\n",
       "12        1.0        0.0        0.0       1       0       0        1\n",
       "13        1.0        0.0        0.0       1       0       0        1\n",
       "14        1.0        0.0        0.0       1       0       0        1\n",
       "15        0.0        0.0        1.0       0       1       0        0\n",
       "16        0.0        0.0        1.0       0       0       1        1\n",
       "17        0.0        1.0        0.0       0       1       0        1\n",
       "18        0.0        1.0        0.0       0       1       0        1\n",
       "19        0.0        0.0        1.0       0       0       1        1\n",
       "20        1.0        0.0        0.0       1       0       0        1\n",
       "21        0.0        0.0        1.0       0       0       1        1\n",
       "22        1.0        0.0        0.0       1       0       0        1\n",
       "23        0.0        0.0        1.0       0       0       1        1\n",
       "24        0.0        0.0        1.0       0       0       1        1\n",
       "25        0.0        0.0        1.0       0       0       1        1\n",
       "26        0.0        1.0        0.0       0       0       1        0\n",
       "27        0.0        0.0        1.0       0       0       1        1\n",
       "28        1.0        0.0        0.0       1       0       0        1\n",
       "29        1.0        0.0        0.0       1       0       0        1\n",
       "..        ...        ...        ...     ...     ...     ...      ...\n",
       "45        0.0        1.0        0.0       0       1       0        1\n",
       "46        0.0        1.0        0.0       0       0       1        0\n",
       "47        0.0        0.0        1.0       0       0       1        1\n",
       "48        0.0        0.0        1.0       0       1       0        0\n",
       "49        0.0        0.0        1.0       0       0       1        1\n",
       "50        0.0        1.0        0.0       0       1       0        1\n",
       "51        0.0        0.0        1.0       0       0       1        1\n",
       "52        0.0        0.0        1.0       0       1       0        0\n",
       "53        1.0        0.0        0.0       1       0       0        1\n",
       "54        0.0        1.0        0.0       0       0       1        0\n",
       "55        0.0        1.0        0.0       0       1       0        1\n",
       "56        1.0        0.0        0.0       1       0       0        1\n",
       "57        1.0        0.0        0.0       1       0       0        1\n",
       "58        1.0        0.0        0.0       1       0       0        1\n",
       "59        0.0        1.0        0.0       0       1       0        1\n",
       "60        0.0        0.0        1.0       0       0       1        1\n",
       "61        1.0        0.0        0.0       1       0       0        1\n",
       "62        1.0        0.0        0.0       1       0       0        1\n",
       "63        1.0        0.0        0.0       1       0       0        1\n",
       "64        0.0        1.0        0.0       0       1       0        1\n",
       "65        1.0        0.0        0.0       1       0       0        1\n",
       "66        0.0        1.0        0.0       0       1       0        1\n",
       "67        0.0        0.0        1.0       0       0       1        1\n",
       "68        1.0        0.0        0.0       1       0       0        1\n",
       "69        0.0        1.0        0.0       0       1       0        1\n",
       "70        0.0        0.0        1.0       0       0       1        1\n",
       "71        1.0        0.0        0.0       1       0       0        1\n",
       "72        0.0        0.0        1.0       0       0       1        1\n",
       "73        0.0        0.0        1.0       0       0       1        1\n",
       "74        0.0        1.0        0.0       0       1       0        1\n",
       "\n",
       "[75 rows x 7 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = pd.DataFrame(expectedOutputTest)\n",
    "predictedDF = pd.DataFrame(predictedClasses)\n",
    "correct = pd.DataFrame(correctPredictionCol)\n",
    "frames = [predictedDF, actual, correct]\n",
    "modelTest = pd.concat(frames, axis=1)\n",
    "modelTest.columns = [\"Predicted\",\"Predicted\", \"Predicted\", \"Actual\", \"Actual\", \"Actual\", \"Correct\"]\n",
    "modelTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[29,  0,  0],\n",
       "       [ 0, 14,  9],\n",
       "       [ 0,  3, 20]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualAsClassNumber = [0]*expectedOutputTest.shape[0]\n",
    "predictedAsClassNumber = [0]*expectedOutputTest.shape[0]\n",
    "for i in range(expectedOutputTest.shape[0]):\n",
    "    actualAsClassNumber[i] = expectedOutputTest[i].tolist().index(1)\n",
    "    predictedAsClassNumber[i] = predictedClasses[i].tolist().index(1.0)\n",
    "confusion_matrix(actualAsClassNumber, predictedAsClassNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "expectedOutputSVM = data.loc[:,4]\n",
    "inputTrain, inputTest, expectedOutputTrain, expectedOutputTest = train_test_split(dataInputs, expectedOutputSVM, train_size = trainPercent/100, random_state=42)\n",
    "clf.fit(inputTrain, expectedOutputTrain)\n",
    "accuracy = clf.score(inputTest, expectedOutputTest)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29,  0,  0],\n",
       "       [ 0, 23,  0],\n",
       "       [ 0,  1, 22]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM One vs all classifier\n",
    "clf = Pipeline([\n",
    "    ('clf', OneVsRestClassifier(LinearSVC()))])\n",
    "model = clf.fit(inputTrain, expectedOutputTrain)\n",
    "accuracy = clf.score(inputTest, expectedOutputTest)\n",
    "print(accuracy)\n",
    "svmPredicted = model.predict(inputTest)\n",
    "confusion_matrix(expectedOutputTest,svmPredicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
